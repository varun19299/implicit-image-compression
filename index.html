<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>Implicit Image Compression</title>

    <meta name="description" content="Implicit Image Compression">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- <base href="/"> -->

    <!--FACEBOOK-->
    <meta property="og:image" content="img/restoration.png">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1024">
    <meta property="og:image:height" content="512">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://varun19299.github.io/implicit-image-compression" />
    <meta property="og:title" content="Implicit Image Compression" />
    <meta property="og:description" content="Project page for Implicit Image Compression." />

    <!--TWITTER-->
    <meta name="twitter:card" content="summary" />
    <meta name=”twitter:site” content=”https://varun19299.github.io/implicit-image-compression/" />
    <meta name="twitter:title" content="Implicit Image Compression" />
    <meta name="twitter:description" content="Project page for Implicit Image Compression." />
    <meta name="twitter:image" content="https://varun19299.github.io/implicit-image-compression/img/restoration.png" />


    <!--     <link rel="apple-touch-icon" href="apple-touch-icon.png"> -->
    <!-- <link rel="icon" type="image/png" href="img/restoration.png"> -->
    <!-- Place favicon.ico in the root directory -->

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <!-- Insert Script here -->

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>

    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                Implicit Image Compression <br>
            </h2>
            <h3 class="col-md-12 text-center">
                CS766 Project, Spring 2021 <br>
            </h3>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="">
                            Megh Doshi
                        </a>
                    </li>
                    <li>
                        <a href="https://varun19299.github.io">
                            Varun Sundar
                        </a>
                    </li>
                    <li>
                        <a href="">
                            Zachary Huemann
                        </a>
                    </li>
                    </br> University of Wisconsin Madison
                </ul>
            </div>
        </div>


        <div class="row">
            <div class="col-md-4 col-md-offset-4 text-center">
                <ul class="nav nav-pills nav-justified">
                    <li>
                        <a href="docs/proposal.pdf">
                            <image src="img/ff_paper_proposal.png" height="60px">
                                <h4><strong>Proposal</strong></h4>
                        </a>
                    </li>
                    <li>
                        <a href="docs/mid_term.pdf">
                            <image src="img/ff_paper_mid_term.png" height="60px">
                                <h4><strong>Midterm</strong></h4>
                        </a>
                    </li>
                    <li>
                        <a href="https://github.com/varun19299/implicit-image-compression">
                            <image src="img/github.png" height="60px">
                                <h4><strong>Code</strong></h4>
                        </a>
                    </li>
                    <li>
                        <a href="https://wandb.ai/implicit-image">
                            <image src="img/wandb.png" height="60px">
                                <h4><strong>Plots</strong></h4>
                        </a>
                    </li>
                </ul>
            </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract & Method
                </h3>
                Implicit Neural Networks, being a continuous mapping, can serve as a compelling choice for representing
                a varietyof commonly encountered 2D and 3D signals.
                In this project, we specifically consider the task of image compressionvia implicit networks.
                Unfortunately, owing to the over-parameterized nature of deep networks, a naive approach mayrequire more
                parameters than samples present in the original signal.
                Furthermore, the capacity of such networks oftensaturates with increasing width or depth.
                We explored two related directions: (a) efficiently increasing thecapacity of implicit MLPs to fit
                natural images, and
                (b) reducing the storage requirement of such networks through acombination of structured hashing,
                quantization and entropy coding.
                <br>
                <figure>
                    <image src="img/idea.png" width="800px" height="350px" />
                    <figcaption><b>Method overview.</b> We propose to use a pipeline similar to JPEG with two major
                        differences: (a) instead of a discrete cosine or wavelet transform (DCT or DWT),
                        we use a MLP (b) we efficiently store the network's weights as opposed to storing the
                        corresponding DCT or DWT coefficients.</figcaption>
                </figure>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    7 Minute Talk
                </h3>

                <br>
                <p align="center">
                <div class="embed-responsive embed-responsive-16by9">
                    <!-- width="600" height="338" -->
                    <iframe src="https://www.youtube.com/embed/Nxs8LtZ-dpU" frameborder="0"
                        allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
                        allowfullscreen></iframe>
                </div>
                </p>

                <table align=center width=800px>
                    <br>
                    <tr>
                        <center>
                            <span style="font-size:22px">&nbsp;<a
                                    href='https://drive.google.com/file/d/1ZLSFL4CL7cXeVW0lQCNm2D6-nvVkW9BK/view?usp=sharing'>[Slides]</a>
                </table>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Motivation & Goals
                </h3>
                <br>
                <p>
                    A large proportion of recent success in a variety of computer vision (and graphics) problems has
                    been attributed
                    to implicitly defined representations parameterized by neural networks (typically a MLP).
                    These include works on novel viewpoint rendering (Mildenhall et al., 2020; Martin-Brualla et al.,
                    2020),
                    image stabililization (Liu et al., 2021) and view-consistent image generation (Schwarz et al., 2020;
                    Chan et al., 2020).
                    Such MLPs replace traditional grid-based representations, and map low-dimensional coordinates to
                    output quantities such as pixel intensities or densities.
                    Their inherent continuous and differentiable nature makes these representations a compelling choice.
                    Additionally, in theparticular case of 3D points, such networks are often much more compact than
                    grid-based representations. Following Tancik et al. (2020), we shall refer to such neural networks
                    as “coordinate MLPs”.
                </p>
                <p>
                    In this work, we examine if these benefits can be carried over to the simpler 2D case of images. We
                    consider applying coordinate MLPs for the task of lossy image compression by mapping 2D
                    grid-locations(x,y)∈[0,1]2to RGB intensities.
                    By fitting a MLP, we transfer the task of compressing a grid of pixels to compressing the
                    corresponding network’s weights. The representation is no longer limited by the grid-resolution but
                    by the underlying network architecture.
                    This however can be challenging since deep networks often have more parameters than data points
                    itself.However, a wide body of research addresses the efficient storage and inference of deep
                    networks,
                    although generallytargeted towards high-dimensional mapping tasks such as image classification.
                </p>
                <p>
                    Another challenge associated with coordinate MLPs is their diminishing increase in capacity with
                    growing layerwidth and depth. This makes representing signals which are densely sampled (large
                    resolution) or with finer detail difficult.
                    Rebain et al. (2020) tackle this issue for the case of 3D points by decomposing the scene into soft
                    Voronoidiagrams and dedicating smaller networks for each part.
                    For images, frequency domain and wavelet decompositionsare potential candidates to achieve similar
                    workarounds.
                </p>
                </ul>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Target Questions
                </h3>
                <br />
                <ul>
                    <li>Given a target image to fit, how can we train and efficiently store coordinate MLPs? Since image
                        quality is usually sacrificed for storage space, we are interested in exploring the trade-off
                        space for coordinate MLPs and comparing them to conventionally used image compression algorithms
                        such as JPEG.</li>
                    <li>For a fixed number of network parameters, can image decomposition help overcome the diminishing
                        returns of naively scaling coordinate MLPs? Valuable insights could include understanding when
                        such decompositions are useful and the range of image resolutions that can be represented.</li>
                </ul>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Approach
                </h3>
                <br>


                </ul>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Implementation
                </h3>
                <br>
                <p>
                    As illustrated in Figure 1, our pipeline first fits a coordinate MLP to an image, either directly or
                    indirectly via a synthesisequation.
                    We then prune and quantize this network, before storing its weights as a compressed sparse array.
                    Althoughrepresented sequentially,
                    we may choose to perform some of these steps jointly with training, e.g. directly train sparseMLPs
                    instead of pruning post-training.
                    Given the rich body of literature in training neural networks efficiently, we baseour design choices
                    on empirical evaluation presented in this section.
                </p>
                <figure>
                    <image src="img/test_images.png" width="100%" height="100%" />
                    <figcaption><b>Figure 2: Test images from the Image Compression Suite</b> ,chosen to include images
                        that are JPEG compressible tovarying extents.
                        The Image Compression Benchmark offers both 8-bit and 16-bit—as well as linear and tonemapped
                        variants of test images—so we prefer it over the standard Kodak dataset (Franzen, 1999) for
                        developing our method.
                        However, when benchmarking the final method, we shall utilize the latter dataset.</figcaption>
                </figure>
                <br>
                <p>
                    We use three 16-bit, uncompressed images from the Image Compresssion Benchmark: flowerfoveon,
                    bigbuilding and bridge (Figure 2).
                    In Figure 3, we present the results of JPEG compression on the three images. We train coordinate
                    MLPs for 10,000 gradient steps each, using the Adam optimizer (Loshchilov and Hutter, 2019) and MSE
                    loss
                    as the objective. Where possible, we set the batch size equal to the total number of pixels—hence
                    corresponding tofull-batch gradient descent. All our experiments are conducted on a NVIDIA GTX-1080
                    GPU with 8GB of VRAM.
                </p>
                <figure>
                    <image src="img/jpeg_psnr_size_vs_quality.png" width="100%" height="100%" />
                    <figcaption><b>Figure 3: JPEG performance in terms of PSNR and storage space versus quality, </b>
                        evaluated on test images fromthe Image Compression Benchmark.
                        PSNR is computed between the 8-bit uncompressed image and the JPEG encodedimage. Storage space
                        is the actual space on disk in kilobytes, encoded using theOpenCVlibrary (Bradski, 2000).
                    </figcaption>
                </figure>
                <br>


                <p>
                    Network Architecture. We compare two recently proposed architectures for enabling MLPs to better
                    represent high-frequency detail in low-dimensional problems: SIREN (Sitzmann et al., 2020) and
                    Fourier Features (Tancik et al.,2020).
                    While SIREN uses sinusoidal activation functions with a particular weight initialization, Fourier
                    Features—abreviated here as FFNet—uses a random Fourier embeddings (Rahimi and Recht, 2008)
                    to increase input dimensionsprior to a ReLU MLP. As seen in Figure 4, for a given number of
                    parameters, SIREN significantly outperforms FFNetin image fitting.
                </p>
                <figure>
                    <image src="img/width_depth.png" width="100%" height="100%" />
                    <figcaption><b>Figure 4: SIREN and FFNet compared across various width, depth configurations. </b>
                        We find SIREN (Sitzmannet al., 2020) to consistently outperform Fourier-Feature networks
                        (FFNet, Tancik et al. (2020)) for all images andconfigurations. Increasing width and depth
                        consistently improves performance for SIREN and less so for FFNet, butrequires greater
                        compression ratios.
                        We set the map size of the random Fourier features as 256, with frequenciessampled fromN(0,σ=
                        16).</figcaption>
                </figure>
                <br>

                <p>
                    By considering the maximum PSNR (equivalently PSNR at quality 100) obtained by JPEG, we choose a
                    SIRENnetwork with depth 8 (or 6 hidden layers) and width 128 as our baseline MLP.
                    We also observe that the minimalarchitecture that outperforms JPEG in PSNR can differ across
                    images—a hidden layer width of 256 units is better suitedfor thebigbuildingandbridgeimages.
                    Table 1 summarises the architecture, performance and storage space forthe chosen baselines.
                    The encoding time required per image is around 20 minutes (10,000 steps), while decoding timeis much
                    smaller, around 30 milliseconds, all reported with a GPU device.
                </p>
                <p>
                    We compare four different techniques to reduce parameter count,
                    viz.,Small-Dense,Feathermap,RigLandPruning.Small-Denseinvolves reducing the hidden-layer width
                    commensurately to achieve a target parameter count.
                    Feathermap is a recently proposed structured hashing technique that represents the entire weights
                    and biases of the MLP by asingle matrix and then stores it via low-rank decomposition.
                    Particularly, we findFeathermapto drastically hurt therepresentation power of the underlying SIREN
                    network.
                    Pruninghere refers to iterative pruning (Zhu and Gupta,2018), where low-magnitude weights are
                    gradually removed from a fully-connected MLP till the desired sparsity isachieved.
                    RigL(Evci et al., 2020) instead directly trains sparse networks from scratch, with periodic growth,
                    pruningand redistribution steps.
                    Overall, we findRigLto be the best approach for lowering parameter-count without significantPSNR
                    loss (Figure 5).
                </p>
                <figure>
                    <image src="img/weight_removal.png" width="100%" height="100%" />
                    <figcaption><b>Figure 5: Weight compression techniques evaluated on test images. </b> We compare
                        using a narrow hiddenlayer (akaSmall-Dense), structured hashing (Feathermap, Eban et al.
                        (2020)),
                        iterative pruning (Pruning, Zhu and Gupta (2018))and dynamic-sparse training (RigL, Evci et al.
                        (2020)).RigLoutperforms all other approaches, especially at highersparsities.
                        Interestingly we can cut up to 80% of the original weights while incurring just a moderate drop
                        in PSNR.</figcaption>
                </figure>

                <br>
                <p>
                    Low bit-rate via extreme sparsity. We qualitative illustrate the benefit of using sparse coordinate
                    MLPs to achievecompression.
                    As before, we useRigLto directly train sparse networks, but at much higher sparsity rates: 90%
                    and95%, corresponding to a parameter count reduction of 10×and 20×respectively.
                    By shifting toint8quantization,which reduces bits required by4xand storing these weights in the
                    Compressed Sparse Column (CSC) format, we canevaluate the theoretical bit-rates.
                    As seen in Figure 6, even at high compression ratios, our approach retains most ofthe visual
                    structure and does not suffer from block artefacts.
                </p>
                <figure>
                    <image src="img/low_bit_rate_case.png" width="100%" height="100%" />
                    <figcaption><b>Figure 6: Qualitative comparison of JPEG versus our method in the low bit-rate
                            regime. </b> Unlike JPEG, the proposed approach does not lead to any blockartefacts
                        under severe compression. Compression ratios for our method are estimated, assuming weight
                        reduction usingRigLandint8quantization—withoutany entropy coding.
                        Quantization produces a fixed compression of4×, whilesparsity is used as a toggle to achieve the
                        target bit-rates. Zoom in to see details.</figcaption>
                </figure>
                <br>
                <p>
                    Wavelet Fitting. We attempt to increase the representation capacity of coordinate MLPs via wavelet
                    decomposition.
                    We use the Daubechies-3 wavelet to perform decompose an image and fit a MLP each to low-frequency
                    and high-frequency components—bothjointly optimized from scratch.
                    For RGB images, we predict low-frequency outputs in the YCbCr space and then simply upsample the
                    chroma components.
                    Unfortunately, this approach does not confer any benefit over directly fitting animage (Figure 7).
                </p>
                <figure>
                    <image src="img/wavelet_comparison.png" width="100%" height="100%" />
                    <figcaption><b>Figure 7: Wavelet decompositiondoes not improve performance.</b> For a fair
                        comparison,
                        we use thesame overall parameter count in either approach. At the parametercounts considered,
                        directly fittingthe image performs better.</figcaption>
                </figure>
                <br>
                <p>
                    Weight Quantization. Training with half precision (float16) or with surrogate quantization modules
                    that simulate int8 precision can reducethe possible performance drop due to post-training
                    quantization,
                    while still maintaining full precision (float32) PSNR.Amongst post-training quantization techniques,
                    we shall consider k-means or centroid based clustering, range basedquantization and distribution
                    based quantization.
                    Han et al. (2015) finds that in the image-classification domain, fully-connected layers can be
                    represented with just 5-bits—although we expect more bits (6-8) required for the significantlyharder
                    image-fitting problem.
                    Yet another alternative is to use the SZ lossy algorithm (Di and Cappello, 2016), althoughthis can
                    be harder to implement (lots of carefully crafted stages, not widely supported).
                </p>
                <p>
                    Post pruning and quantization, we are left with a bunch of sparse matrices that need to be
                    efficiently stored.
                    We shalluse the Compressed Sparse Columns (CSC) format, which stores2η(n×m) +m+ 1numbers for a
                    matrix of sizen×mand sparsityη.
                    We note that since no pruning is performed on the bias vectors, these can be represented as
                    densearrays.
                    The stored matrices can now be compressed by a combination of common entropy coding techniques such
                    ashuffman encoding, LZ77 or the more recent proposed ZStandard.
                </p>

                </ul>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                    This website template was borrowed from <a href="http://mgharbi.com/">Michaël Gharbi</a> and
                    <a href="https://www.matthewtancik.com">Matthew Tannick</a>.
                </p>
            </div>
        </div>
    </div>
</body>

</html>